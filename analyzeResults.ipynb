{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce46f46a-dbbb-4ad5-872c-c2616f73fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repeated Measures ANOVA ===\n",
      "                   Anova\n",
      "============================================\n",
      "             F Value   Num DF  Den DF Pr > F\n",
      "--------------------------------------------\n",
      "token_count 24268.2288 2.0000 98.0000 0.0000\n",
      "============================================\n",
      "\n",
      "\n",
      "=== Pairwise Comparisons (Bonferroni-Corrected) ===\n",
      "500000 vs 1000000 → t = 117.9388, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "500000 vs 2000000 → t = 220.8192, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "1000000 vs 2000000 → t = 97.6873, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "\n",
      "=== Shapiro-Wilk Normality Test ===\n",
      "500000: W = 0.9755, p = 0.3796 → Normal\n",
      "1000000: W = 0.9735, p = 0.3200 → Normal\n",
      "2000000: W = 0.9880, p = 0.8872 → Normal\n",
      "\n",
      "=== Mauchly’s Test for Sphericity ===\n",
      "SpherResults(spher=True, W=inf, chi2=-inf, dof=2, pval=1.0)\n",
      "\n",
      "=== Repeated Measures ANOVA (Pingouin) ===\n",
      "        Source            SS  DF            MS             F          p-unc  \\\n",
      "0  token_count  5.316590e-20   2  2.658295e-20  24268.228843  8.124898e-133   \n",
      "1        Error  1.073473e-22  98  1.095381e-24           NaN            NaN   \n",
      "\n",
      "        ng2       eps  \n",
      "0  0.997147  0.742522  \n",
      "1       NaN       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pingouin/distribution.py:1004: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  W = np.prod(eig) / (eig.sum() / d) ** d\n",
      "/opt/conda/lib/python3.12/site-packages/pingouin/distribution.py:1004: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  W = np.prod(eig) / (eig.sum() / d) ** d\n"
     ]
    }
   ],
   "source": [
    "# === Required Libraries ===\n",
    "# Run this once if needed:\n",
    "# pip install pingouin statsmodels scipy pandas\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import ttest_rel, shapiro\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pingouin as pg\n",
    "from itertools import combinations\n",
    "\n",
    "# === Step 1: Load and combine data from all token levels ===\n",
    "df_500k = pd.read_csv(\"FUPowerResults/500000_tokens/run_log.csv\")\n",
    "df_500k[\"token_count\"] = 500000\n",
    "\n",
    "df_1m = pd.read_csv(\"FUPowerResults/1000000_tokens/run_log.csv\")\n",
    "df_1m[\"token_count\"] = 1000000\n",
    "\n",
    "df_2m = pd.read_csv(\"FUPowerResults/2000000_tokens/run_log.csv\")\n",
    "df_2m[\"token_count\"] = 2000000\n",
    "\n",
    "df_all = pd.concat([df_500k, df_1m, df_2m], ignore_index=True)\n",
    "df_all = df_all[[\"trial_number\", \"token_count\", \"parameter_efficiency\"]]\n",
    "\n",
    "# === Step 2: Run Repeated Measures ANOVA ===\n",
    "anova = AnovaRM(df_all, depvar=\"parameter_efficiency\", subject=\"trial_number\", within=[\"token_count\"]).fit()\n",
    "print(\"\\n=== Repeated Measures ANOVA ===\")\n",
    "print(anova)\n",
    "\n",
    "# === Step 3: Prepare data for pairwise testing and assumptions ===\n",
    "df_wide = df_all.pivot(index=\"trial_number\", columns=\"token_count\", values=\"parameter_efficiency\")\n",
    "pairs = list(combinations(df_wide.columns, 2))\n",
    "\n",
    "# === Step 4: Pairwise Bonferroni-Corrected Dependent T-Tests ===\n",
    "print(\"\\n=== Pairwise Comparisons (Bonferroni-Corrected) ===\")\n",
    "p_values = []\n",
    "results = []\n",
    "\n",
    "for a, b in pairs:\n",
    "    t_stat, p = ttest_rel(df_wide[a], df_wide[b])\n",
    "    p_values.append(p)\n",
    "    results.append((a, b, t_stat, p))\n",
    "\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')\n",
    "\n",
    "for i, (a, b, t_stat, raw_p) in enumerate(results):\n",
    "    print(f\"{a} vs {b} → t = {t_stat:.4f}, raw p = {raw_p:.4f}, corrected p = {pvals_corrected[i]:.4f}, reject H₀: {reject[i]}\")\n",
    "\n",
    "# === Step 5: Normality Check (Shapiro-Wilk) ===\n",
    "print(\"\\n=== Shapiro-Wilk Normality Test ===\")\n",
    "for token in df_wide.columns:\n",
    "    stat, p = shapiro(df_wide[token])\n",
    "    print(f\"{token}: W = {stat:.4f}, p = {p:.4f} → {'Normal' if p > 0.05 else 'Non-normal'}\")\n",
    "\n",
    "# === Step 6: Mauchly’s Test for Sphericity ===\n",
    "print(\"\\n=== Mauchly’s Test for Sphericity ===\")\n",
    "df_long = pd.melt(df_wide.reset_index(), id_vars='trial_number', var_name='token_count', value_name='efficiency')\n",
    "df_long['token_count'] = df_long['token_count'].astype(str)\n",
    "\n",
    "sphericity_test = pg.sphericity(data=df_long, dv='efficiency', subject='trial_number', within='token_count')\n",
    "print(sphericity_test)\n",
    "\n",
    "# === Step 7: Detailed ANOVA with Pingouin (Optional) ===\n",
    "print(\"\\n=== Repeated Measures ANOVA (Pingouin) ===\")\n",
    "aov_pg = pg.rm_anova(dv='efficiency', within='token_count', subject='trial_number', data=df_long, detailed=True)\n",
    "print(aov_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51c5a8db-4656-4320-85dc-6599b1e6e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repeated Measures ANOVA ===\n",
      "                   Anova\n",
      "===========================================\n",
      "             F Value  Num DF  Den DF Pr > F\n",
      "-------------------------------------------\n",
      "token_count 3143.2063 2.0000 98.0000 0.0000\n",
      "===========================================\n",
      "\n",
      "\n",
      "=== Pairwise Comparisons (Bonferroni-Corrected) ===\n",
      "500000 vs 1000000 → t = -40.6892, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "500000 vs 2000000 → t = -84.1646, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "1000000 vs 2000000 → t = -36.6477, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "\n",
      "=== Shapiro-Wilk Normality Test ===\n",
      "500000: W = 0.9799, p = 0.5475 → Normal\n",
      "1000000: W = 0.8175, p = 0.0000 → Non-normal\n",
      "2000000: W = 0.9487, p = 0.0300 → Non-normal\n",
      "\n",
      "=== Mauchly’s Test for Sphericity ===\n",
      "SpherResults(spher=False, W=0.4218734064626523, chi2=41.42639974253711, dof=2, pval=1.01011679792576e-09)\n",
      "\n",
      "=== Repeated Measures ANOVA (Pingouin) ===\n",
      "        Source           SS  DF           MS            F         p-unc  \\\n",
      "0  token_count  3360.174036   2  1680.087018  3143.206296  1.315683e-89   \n",
      "1        Error    52.382349  98     0.534514          NaN           NaN   \n",
      "\n",
      "      p-GG-corr       ng2       eps sphericity   W-spher       p-spher  \n",
      "0  9.602643e-58  0.968508  0.633663      False  0.421873  1.010117e-09  \n",
      "1           NaN       NaN       NaN        NaN       NaN           NaN  \n"
     ]
    }
   ],
   "source": [
    "# === Required Libraries ===\n",
    "# Run this once if needed:\n",
    "# pip install pingouin statsmodels scipy pandas\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import ttest_rel, shapiro\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pingouin as pg\n",
    "from itertools import combinations\n",
    "\n",
    "# === Step 1: Load and combine data from all token levels ===\n",
    "df_500k = pd.read_csv(\"FUPowerResults/500000_tokens/run_log.csv\")\n",
    "df_500k[\"token_count\"] = 500000\n",
    "\n",
    "df_1m = pd.read_csv(\"FUPowerResults/1000000_tokens/run_log.csv\")\n",
    "df_1m[\"token_count\"] = 1000000\n",
    "\n",
    "df_2m = pd.read_csv(\"FUPowerResults/2000000_tokens/run_log.csv\")\n",
    "df_2m[\"token_count\"] = 2000000\n",
    "\n",
    "df_all = pd.concat([df_500k, df_1m, df_2m], ignore_index=True)\n",
    "df_all = df_all[[\"trial_number\", \"token_count\", \"watts_rms\"]]\n",
    "\n",
    "# === Step 2: Run Repeated Measures ANOVA ===\n",
    "anova = AnovaRM(df_all, depvar=\"watts_rms\", subject=\"trial_number\", within=[\"token_count\"]).fit()\n",
    "print(\"\\n=== Repeated Measures ANOVA ===\")\n",
    "print(anova)\n",
    "\n",
    "# === Step 3: Prepare data for pairwise testing and assumptions ===\n",
    "df_wide = df_all.pivot(index=\"trial_number\", columns=\"token_count\", values=\"watts_rms\")\n",
    "pairs = list(combinations(df_wide.columns, 2))\n",
    "\n",
    "# === Step 4: Pairwise Bonferroni-Corrected Dependent T-Tests ===\n",
    "print(\"\\n=== Pairwise Comparisons (Bonferroni-Corrected) ===\")\n",
    "p_values = []\n",
    "results = []\n",
    "\n",
    "for a, b in pairs:\n",
    "    t_stat, p = ttest_rel(df_wide[a], df_wide[b])\n",
    "    p_values.append(p)\n",
    "    results.append((a, b, t_stat, p))\n",
    "\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')\n",
    "\n",
    "for i, (a, b, t_stat, raw_p) in enumerate(results):\n",
    "    print(f\"{a} vs {b} → t = {t_stat:.4f}, raw p = {raw_p:.4f}, corrected p = {pvals_corrected[i]:.4f}, reject H₀: {reject[i]}\")\n",
    "\n",
    "# === Step 5: Normality Check (Shapiro-Wilk) ===\n",
    "print(\"\\n=== Shapiro-Wilk Normality Test ===\")\n",
    "for token in df_wide.columns:\n",
    "    stat, p = shapiro(df_wide[token])\n",
    "    print(f\"{token}: W = {stat:.4f}, p = {p:.4f} → {'Normal' if p > 0.05 else 'Non-normal'}\")\n",
    "\n",
    "# === Step 6: Mauchly’s Test for Sphericity ===\n",
    "print(\"\\n=== Mauchly’s Test for Sphericity ===\")\n",
    "df_long = pd.melt(df_wide.reset_index(), id_vars='trial_number', var_name='token_count', value_name='watts_rms')\n",
    "df_long['token_count'] = df_long['token_count'].astype(str)\n",
    "\n",
    "sphericity_test = pg.sphericity(data=df_long, dv='watts_rms', subject='trial_number', within='token_count')\n",
    "print(sphericity_test)\n",
    "\n",
    "# === Step 7: Detailed ANOVA with Pingouin (Optional) ===\n",
    "print(\"\\n=== Repeated Measures ANOVA (Pingouin) ===\")\n",
    "aov_pg = pg.rm_anova(dv='watts_rms', within='token_count', subject='trial_number', data=df_long, detailed=True)\n",
    "print(aov_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728e773-7feb-4df5-bb94-096b4e963061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

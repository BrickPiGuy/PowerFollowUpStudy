{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46f46a-dbbb-4ad5-872c-c2616f73fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Required Libraries ===\n",
    "# Run this once if needed:\n",
    "# pip install pingouin statsmodels scipy pandas\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import ttest_rel, shapiro\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pingouin as pg\n",
    "from itertools import combinations\n",
    "\n",
    "# === Step 1: Load and combine data from all token levels ===\n",
    "df_500k = pd.read_csv(\"results/500000_tokens/run_log-edit.csv\")\n",
    "df_500k[\"token_count\"] = 500000\n",
    "\n",
    "df_1m = pd.read_csv(\"results/1000000_tokens/run_log-edit.csv\")\n",
    "df_1m[\"token_count\"] = 1000000\n",
    "\n",
    "df_2m = pd.read_csv(\"results/2000000_tokens/run_log-edit.csv\")\n",
    "df_2m[\"token_count\"] = 2000000\n",
    "\n",
    "df_all = pd.concat([df_500k, df_1m, df_2m], ignore_index=True)\n",
    "df_all = df_all[[\"trial_number\", \"token_count\", \"parameter_efficiency\"]]\n",
    "\n",
    "# === Step 2: Run Repeated Measures ANOVA ===\n",
    "anova = AnovaRM(df_all, depvar=\"parameter_efficiency\", subject=\"trial_number\", within=[\"token_count\"]).fit()\n",
    "print(\"\\n=== Repeated Measures ANOVA ===\")\n",
    "print(anova)\n",
    "\n",
    "# === Step 3: Prepare data for pairwise testing and assumptions ===\n",
    "df_wide = df_all.pivot(index=\"trial_number\", columns=\"token_count\", values=\"parameter_efficiency\")\n",
    "pairs = list(combinations(df_wide.columns, 2))\n",
    "\n",
    "# === Step 4: Pairwise Bonferroni-Corrected Dependent T-Tests ===\n",
    "print(\"\\n=== Pairwise Comparisons (Bonferroni-Corrected) ===\")\n",
    "p_values = []\n",
    "results = []\n",
    "\n",
    "for a, b in pairs:\n",
    "    t_stat, p = ttest_rel(df_wide[a], df_wide[b])\n",
    "    p_values.append(p)\n",
    "    results.append((a, b, t_stat, p))\n",
    "\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')\n",
    "\n",
    "for i, (a, b, t_stat, raw_p) in enumerate(results):\n",
    "    print(f\"{a} vs {b} → t = {t_stat:.4f}, raw p = {raw_p:.4f}, corrected p = {pvals_corrected[i]:.4f}, reject H₀: {reject[i]}\")\n",
    "\n",
    "# === Step 5: Normality Check (Shapiro-Wilk) ===\n",
    "print(\"\\n=== Shapiro-Wilk Normality Test ===\")\n",
    "for token in df_wide.columns:\n",
    "    stat, p = shapiro(df_wide[token])\n",
    "    print(f\"{token}: W = {stat:.4f}, p = {p:.4f} → {'Normal' if p > 0.05 else 'Non-normal'}\")\n",
    "\n",
    "# === Step 6: Mauchly’s Test for Sphericity ===\n",
    "print(\"\\n=== Mauchly’s Test for Sphericity ===\")\n",
    "df_long = pd.melt(df_wide.reset_index(), id_vars='trial_number', var_name='token_count', value_name='efficiency')\n",
    "df_long['token_count'] = df_long['token_count'].astype(str)\n",
    "\n",
    "sphericity_test = pg.sphericity(data=df_long, dv='efficiency', subject='trial_number', within='token_count')\n",
    "print(sphericity_test)\n",
    "\n",
    "# === Step 7: Detailed ANOVA with Pingouin (Optional) ===\n",
    "print(\"\\n=== Repeated Measures ANOVA (Pingouin) ===\")\n",
    "aov_pg = pg.rm_anova(dv='efficiency', within='token_count', subject='trial_number', data=df_long, detailed=True)\n",
    "print(aov_pg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

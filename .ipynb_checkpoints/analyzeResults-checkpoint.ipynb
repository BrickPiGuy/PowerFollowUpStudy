{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce46f46a-dbbb-4ad5-872c-c2616f73fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repeated Measures ANOVA ===\n",
      "                   Anova\n",
      "============================================\n",
      "             F Value   Num DF  Den DF Pr > F\n",
      "--------------------------------------------\n",
      "token_count 24268.2288 2.0000 98.0000 0.0000\n",
      "============================================\n",
      "\n",
      "\n",
      "=== Pairwise Comparisons (Bonferroni-Corrected) ===\n",
      "500000 vs 1000000 → t = 117.9388, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "500000 vs 2000000 → t = 220.8192, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "1000000 vs 2000000 → t = 97.6873, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "\n",
      "=== Shapiro-Wilk Normality Test ===\n",
      "500000: W = 0.9755, p = 0.3796 → Normal\n",
      "1000000: W = 0.9735, p = 0.3200 → Normal\n",
      "2000000: W = 0.9880, p = 0.8872 → Normal\n",
      "\n",
      "=== Mauchly’s Test for Sphericity ===\n",
      "SpherResults(spher=True, W=inf, chi2=-inf, dof=2, pval=1.0)\n",
      "\n",
      "=== Repeated Measures ANOVA (Pingouin) ===\n",
      "        Source            SS  DF            MS             F          p-unc  \\\n",
      "0  token_count  5.316590e-20   2  2.658295e-20  24268.228843  8.124898e-133   \n",
      "1        Error  1.073473e-22  98  1.095381e-24           NaN            NaN   \n",
      "\n",
      "        ng2       eps  \n",
      "0  0.997147  0.742522  \n",
      "1       NaN       NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pingouin/distribution.py:1004: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  W = np.prod(eig) / (eig.sum() / d) ** d\n",
      "/opt/conda/lib/python3.12/site-packages/pingouin/distribution.py:1004: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  W = np.prod(eig) / (eig.sum() / d) ** d\n"
     ]
    }
   ],
   "source": [
    "# === Required Libraries ===\n",
    "# Run this once if needed:\n",
    "# pip install pingouin statsmodels scipy pandas\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import ttest_rel, shapiro\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pingouin as pg\n",
    "from itertools import combinations\n",
    "\n",
    "# === Step 1: Load and combine data from all token levels ===\n",
    "df_500k = pd.read_csv(\"FUPowerResults/500000_tokens/run_log.csv\")\n",
    "df_500k[\"token_count\"] = 500000\n",
    "\n",
    "df_1m = pd.read_csv(\"FUPowerResults/1000000_tokens/run_log.csv\")\n",
    "df_1m[\"token_count\"] = 1000000\n",
    "\n",
    "df_2m = pd.read_csv(\"FUPowerResults/2000000_tokens/run_log.csv\")\n",
    "df_2m[\"token_count\"] = 2000000\n",
    "\n",
    "df_all = pd.concat([df_500k, df_1m, df_2m], ignore_index=True)\n",
    "df_all = df_all[[\"trial_number\", \"token_count\", \"parameter_efficiency\"]]\n",
    "\n",
    "# === Step 2: Run Repeated Measures ANOVA ===\n",
    "anova = AnovaRM(df_all, depvar=\"parameter_efficiency\", subject=\"trial_number\", within=[\"token_count\"]).fit()\n",
    "print(\"\\n=== Repeated Measures ANOVA ===\")\n",
    "print(anova)\n",
    "\n",
    "# === Step 3: Prepare data for pairwise testing and assumptions ===\n",
    "df_wide = df_all.pivot(index=\"trial_number\", columns=\"token_count\", values=\"parameter_efficiency\")\n",
    "pairs = list(combinations(df_wide.columns, 2))\n",
    "\n",
    "# === Step 4: Pairwise Bonferroni-Corrected Dependent T-Tests ===\n",
    "print(\"\\n=== Pairwise Comparisons (Bonferroni-Corrected) ===\")\n",
    "p_values = []\n",
    "results = []\n",
    "\n",
    "for a, b in pairs:\n",
    "    t_stat, p = ttest_rel(df_wide[a], df_wide[b])\n",
    "    p_values.append(p)\n",
    "    results.append((a, b, t_stat, p))\n",
    "\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')\n",
    "\n",
    "for i, (a, b, t_stat, raw_p) in enumerate(results):\n",
    "    print(f\"{a} vs {b} → t = {t_stat:.4f}, raw p = {raw_p:.4f}, corrected p = {pvals_corrected[i]:.4f}, reject H₀: {reject[i]}\")\n",
    "\n",
    "# === Step 5: Normality Check (Shapiro-Wilk) ===\n",
    "print(\"\\n=== Shapiro-Wilk Normality Test ===\")\n",
    "for token in df_wide.columns:\n",
    "    stat, p = shapiro(df_wide[token])\n",
    "    print(f\"{token}: W = {stat:.4f}, p = {p:.4f} → {'Normal' if p > 0.05 else 'Non-normal'}\")\n",
    "\n",
    "# === Step 6: Mauchly’s Test for Sphericity ===\n",
    "print(\"\\n=== Mauchly’s Test for Sphericity ===\")\n",
    "df_long = pd.melt(df_wide.reset_index(), id_vars='trial_number', var_name='token_count', value_name='efficiency')\n",
    "df_long['token_count'] = df_long['token_count'].astype(str)\n",
    "\n",
    "sphericity_test = pg.sphericity(data=df_long, dv='efficiency', subject='trial_number', within='token_count')\n",
    "print(sphericity_test)\n",
    "\n",
    "# === Step 7: Detailed ANOVA with Pingouin (Optional) ===\n",
    "print(\"\\n=== Repeated Measures ANOVA (Pingouin) ===\")\n",
    "aov_pg = pg.rm_anova(dv='efficiency', within='token_count', subject='trial_number', data=df_long, detailed=True)\n",
    "print(aov_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51c5a8db-4656-4320-85dc-6599b1e6e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Repeated Measures ANOVA ===\n",
      "                   Anova\n",
      "===========================================\n",
      "             F Value  Num DF  Den DF Pr > F\n",
      "-------------------------------------------\n",
      "token_count 3143.2063 2.0000 98.0000 0.0000\n",
      "===========================================\n",
      "\n",
      "\n",
      "=== Pairwise Comparisons (Bonferroni-Corrected) ===\n",
      "500000 vs 1000000 → t = -40.6892, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "500000 vs 2000000 → t = -84.1646, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "1000000 vs 2000000 → t = -36.6477, raw p = 0.0000, corrected p = 0.0000, reject H₀: True\n",
      "\n",
      "=== Shapiro-Wilk Normality Test ===\n",
      "500000: W = 0.9799, p = 0.5475 → Normal\n",
      "1000000: W = 0.8175, p = 0.0000 → Non-normal\n",
      "2000000: W = 0.9487, p = 0.0300 → Non-normal\n",
      "\n",
      "=== Mauchly’s Test for Sphericity ===\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "efficiency not in data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m df_long \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmelt(df_wide\u001b[38;5;241m.\u001b[39mreset_index(), id_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrial_number\u001b[39m\u001b[38;5;124m'\u001b[39m, var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_count\u001b[39m\u001b[38;5;124m'\u001b[39m, value_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatts_rms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     58\u001b[0m df_long[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_long[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m sphericity_test \u001b[38;5;241m=\u001b[39m \u001b[43mpg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msphericity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_long\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mefficiency\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrial_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken_count\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(sphericity_test)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# === Step 7: Detailed ANOVA with Pingouin (Optional) ===\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pingouin/distribution.py:957\u001b[0m, in \u001b[0;36msphericity\u001b[0;34m(data, dv, within, subject, method, alpha)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;66;03m# If data is in long-format, convert to wide-format\u001b[39;00m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m([v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m [dv, within, subject]]):\n\u001b[0;32m--> 957\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_long_to_wide_rm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwithin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[38;5;66;03m# From now on we assume that data is in wide-format and contains only\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;66;03m# the relevant columns.\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;66;03m# Remove rows with missing values in wide-format dataframe\u001b[39;00m\n\u001b[1;32m    962\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/pingouin/distribution.py:538\u001b[0m, in \u001b[0;36m_long_to_wide_rm\u001b[0;34m(data, dv, within, subject)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert long-format dataframe to wide-format.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;124;03mThis internal function is used in pingouin.epsilon and pingouin.sphericity.\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# Check that all columns are present\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dv \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not in data\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m dv\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data[dv]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbfiu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m must be numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m dv\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not in data\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m subject\n",
      "\u001b[0;31mAssertionError\u001b[0m: efficiency not in data"
     ]
    }
   ],
   "source": [
    "# === Required Libraries ===\n",
    "# Run this once if needed:\n",
    "# pip install pingouin statsmodels scipy pandas\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import ttest_rel, shapiro\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import pingouin as pg\n",
    "from itertools import combinations\n",
    "\n",
    "# === Step 1: Load and combine data from all token levels ===\n",
    "df_500k = pd.read_csv(\"FUPowerResults/500000_tokens/run_log.csv\")\n",
    "df_500k[\"token_count\"] = 500000\n",
    "\n",
    "df_1m = pd.read_csv(\"FUPowerResults/1000000_tokens/run_log.csv\")\n",
    "df_1m[\"token_count\"] = 1000000\n",
    "\n",
    "df_2m = pd.read_csv(\"FUPowerResults/2000000_tokens/run_log.csv\")\n",
    "df_2m[\"token_count\"] = 2000000\n",
    "\n",
    "df_all = pd.concat([df_500k, df_1m, df_2m], ignore_index=True)\n",
    "df_all = df_all[[\"trial_number\", \"token_count\", \"watts_rms\"]]\n",
    "\n",
    "# === Step 2: Run Repeated Measures ANOVA ===\n",
    "anova = AnovaRM(df_all, depvar=\"watts_rms\", subject=\"trial_number\", within=[\"token_count\"]).fit()\n",
    "print(\"\\n=== Repeated Measures ANOVA ===\")\n",
    "print(anova)\n",
    "\n",
    "# === Step 3: Prepare data for pairwise testing and assumptions ===\n",
    "df_wide = df_all.pivot(index=\"trial_number\", columns=\"token_count\", values=\"watts_rms\")\n",
    "pairs = list(combinations(df_wide.columns, 2))\n",
    "\n",
    "# === Step 4: Pairwise Bonferroni-Corrected Dependent T-Tests ===\n",
    "print(\"\\n=== Pairwise Comparisons (Bonferroni-Corrected) ===\")\n",
    "p_values = []\n",
    "results = []\n",
    "\n",
    "for a, b in pairs:\n",
    "    t_stat, p = ttest_rel(df_wide[a], df_wide[b])\n",
    "    p_values.append(p)\n",
    "    results.append((a, b, t_stat, p))\n",
    "\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='bonferroni')\n",
    "\n",
    "for i, (a, b, t_stat, raw_p) in enumerate(results):\n",
    "    print(f\"{a} vs {b} → t = {t_stat:.4f}, raw p = {raw_p:.4f}, corrected p = {pvals_corrected[i]:.4f}, reject H₀: {reject[i]}\")\n",
    "\n",
    "# === Step 5: Normality Check (Shapiro-Wilk) ===\n",
    "print(\"\\n=== Shapiro-Wilk Normality Test ===\")\n",
    "for token in df_wide.columns:\n",
    "    stat, p = shapiro(df_wide[token])\n",
    "    print(f\"{token}: W = {stat:.4f}, p = {p:.4f} → {'Normal' if p > 0.05 else 'Non-normal'}\")\n",
    "\n",
    "# === Step 6: Mauchly’s Test for Sphericity ===\n",
    "print(\"\\n=== Mauchly’s Test for Sphericity ===\")\n",
    "df_long = pd.melt(df_wide.reset_index(), id_vars='trial_number', var_name='token_count', value_name='watts_rms')\n",
    "df_long['token_count'] = df_long['token_count'].astype(str)\n",
    "\n",
    "sphericity_test = pg.sphericity(data=df_long, dv='watts_rms', subject='trial_number', within='token_count')\n",
    "print(sphericity_test)\n",
    "\n",
    "# === Step 7: Detailed ANOVA with Pingouin (Optional) ===\n",
    "print(\"\\n=== Repeated Measures ANOVA (Pingouin) ===\")\n",
    "aov_pg = pg.rm_anova(dv='watts_rms', within='token_count', subject='trial_number', data=df_long, detailed=True)\n",
    "print(aov_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728e773-7feb-4df5-bb94-096b4e963061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
